# Design Package Summary: AOF Workflow Gates + Agentic SDLC

**From:** Demerzel  
**Date:** 2026-02-16 22:09 EST  
**Status:** Three design docs completed, ready for your review

---

## Context

You requested that architect and PM design the ideal agentic SDLC. They've delivered three companion documents:

1. **Workflow Gates** (mechanism) — domain-neutral primitive for staged process gates
2. **Agentic SDLC** (reference workflow) — how this looks for SWE teams, codified in AOF
3. **PM Addendum** (operations) — how PM runs it day-to-day

This summary is the headline. Full docs available for detailed review.

---

## Doc 1: Workflow Gates (the mechanism)

**Location:** `~/Projects/AOF/docs/design/WORKFLOW-GATES-DESIGN.md` (37KB)

**What it is:** A domain-neutral primitive that enforces multi-stage process gates on tasks. Works for SWE, sales, content, compliance — any staged workflow.

**Core design:**
- **Gate** = a workflow stage owned by a role (not specific agents). Role maps to agents via org chart.
- **Workflow** = ordered sequence of gates, defined once per project in `project.yaml`
- **Progression** = deterministic routing (pure TypeScript evaluation, zero LLM calls in control plane)

**How agents experience it:**
- Agent receives task with full context in frontmatter
- Agent does work
- Agent calls `aof_task_complete(outcome: "complete", summary: "...")`
- AOF automatically routes to next gate
- **Agent never knows gates exist**

**Rejection mechanism:**
- Reviewer returns `outcome: "needs_review"` with `blockers: [...]`
- AOF routes task back per strategy: `previous` (go back one), `origin` (go back to first), or `named` (specified target)
- Rejection context appended to task
- Task bounces indefinitely until accepted; circular loop detection at 5+ cycles

**Conditional gates:**
```yaml
- id: security
  when: "tags.includes('security') || tags.includes('auth')"
```
Gates skipped automatically if condition is false. JavaScript expressions in sandboxed environment.

**Examples:** SWE pipeline, sales pipeline, content publishing, simple 2-step review.

**Implementation:** 5 phases from MVP (forward progression) → rejection loops → conditional gates → observability → advanced features (parallel gates, human approval, timeouts).

**Open questions for you:**
1. Gate history in frontmatter vs separate file after completion?
2. Support parallel gates (security + docs simultaneously)? (Deferred to v2)
3. Human-only approval gates? (Recommended for v1)

---

## Doc 2: Agentic SDLC (the SWE reference)

**Location:** `~/Projects/AOF/docs/design/AGENTIC-SDLC-DESIGN.md` (68KB)

**What it is:** The ideal software development lifecycle for autonomous agents, expressed as an AOF workflow configuration. Blends XP (especially TDD), continuous delivery, and Accelerate principles.

**The 9-gate pipeline:**

```
backlog
  ↓
ready-check (PM validates task is actionable)
  ↓
implement (dynamic role — backend, frontend, data-eng, etc.)
  ↓
code-review (architect, TDD enforced via git timestamps)
  ↓
qa (QA validates AC met, tests meaningful)
  ↓
security (conditional: security-tagged tasks only)
  ↓
docs (conditional: docs/API changes only)
  ↓
po-accept (PO final sign-off)
  ↓
deploy (conditional: deployable projects only; SRE-owned)
  ↓
done
```

**Rejection routing:** All rejections loop back to `implement` (not "previous gate") because most fixes require code changes. Rejection context appended with specific blockers.

**TDD as non-negotiable:** Architect verifies via git log that tests were committed before implementation code. Rejection if TDD not followed.

**Concrete acceptance/rejection criteria per gate:**

| Gate | Accept If | Reject If |
|------|-----------|-----------|
| code-review | Coverage ≥80%, no files >500 LOC, no functions >120 LOC, TDD followed | Coverage <80%, architectural violations, missing error handling |
| QA | All AC met, tests meaningful, no regressions | AC not met, tests trivial, regression detected |
| docs | API docs updated, clear prose, examples work, links valid | Docs missing, poor writing, broken links |

**Timeouts per gate:** ready-check 30min, implement 4hr (target 2hr), code-review 1hr, QA 2hr, security 3hr, docs 1.5hr, po-accept 1hr, deploy 45min

**Anti-stall guarantee:** If gate exceeds timeout → escalate to PM → architect → PO → dead-letter queue for manual intervention

**Example walkthrough:** Trace of `GET /users/:id` endpoint through full pipeline with 2 rejection loops (architect rejects for missing error handling, tech-writer rejects for missing API docs). Total time: 3.5 hours.

**Key principle:** Rejection is a learning signal, not failure. Fast feedback loops + specific blockers = continuous agent improvement.

---

## Doc 3: PM Addendum (the operational layer)

**Location:** `~/Projects/AOF/docs/design/AGENTIC-SDLC-PM-ADDENDUM.md`

**What it is:** How PM actually runs this — allocation, stall prevention, metrics, retrospectives, flow optimization.

**Sprint planning:**
- **Priority-based allocation:** P0 → P1 → P2 cascade (not velocity-based)
- **Continuous flow:** Tasks pulled as agents complete work (no sprint boundaries)
- **Capacity model:** 1 task per implementer, 3 per reviewer, 2 per QA (allows for parallelism in lower-cognitive roles)

**Task sizing:**
- Hard constraint: Task must complete in single session (2-8 hours)
- If larger: PM decomposes before allocation
- Spikes time-boxed to 2 hours max

**WIP limits (enforced per agent role):**

| Role | Max Concurrent |
|------|----------------|
| Implementer | 1 |
| Architect (reviewer) | 3 |
| QA | 2 |
| Security | 1 |
| PO (approval) | 5 |

Plus system-wide cap: 1.5× number of agents.

**Anti-stall escalation cascade:**
- Gate stuck >4hr (review) or >8hr (implement) → PM alerted
- Task rejected 3+ times → reassign to different agent
- Task rejected 5+ times → dead-letter queue, PM manual review
- Pipeline throughput drops >50% → PM triggers bottleneck analysis

**Metrics (Accelerate-aligned):**
- **DORA:** deployment frequency, lead time for changes, change failure rate, MTTR
- **Gate-specific:** duration, rejection rate, transition counts, active tasks per gate
- **Agent-specific:** throughput, rejection rate, rework cycles
- **Targets:** lead time <4hr, rejection rate <30%, change failure <15%

**Automated retrospectives:**
- Weekly analysis of rejection patterns (which gates, which reasons)
- Bottleneck detection (gates with longest dwell time)
- Agent performance clustering (which agents get rejected most)
- Learnings fed back into agent context automatically

**Coordination boundaries:**
- **PO:** Owns "what to build" (vision, AC, acceptance)
- **Architect:** Owns "how to build" (technical decisions, code review standards)
- **PM:** Owns "when and flow" (allocation, throughput, stall prevention)
- Weekly three-way backlog grooming session

---

## Key Design Decisions (Need Your Input)

### 1. Rejection Routing Flexibility

**Question:** Should all rejections go to `implement`, or can some routes be more specific?

**Current design:** All rejections → implement (because most fixes require code changes)

**Alternative:** QA could reject back to code-review for test quality issues (not code issues)

**Trade-off:**
- All → implement: simpler for agents ("just fix everything and retest")
- Flexible: faster feedback for test-only issues (skip re-implementing)

**Recommendation:** Start with all → implement for v1. Add flexibility in v2 if we see patterns of "test-only" rejections.

### 2. Gate Timeouts Alignment

**Issue:** SDLC doc has specific timeout values (code-review 60min), PM addendum talks about different escalation thresholds (4hr review gate).

**Need:** Finalize concrete timeout values for each gate and escalation triggers.

**Suggest:** Meeting to align SDLC and PM on these numbers.

### 3. Parallel Gates Deferred to v2

**Current design:** Security + docs + QA run **sequentially** (faster wins over ideal throughput)

**Why:** Parallel gates require fork/join logic, significantly more complex

**Impact:** Serial gates add latency (e.g., QA waits for security to finish) but keep implementation simple

**Decision:** Defer parallel gates to v2. Measure actual throughput impact in v1.

---

## Next Steps

1. **Review the three docs** in this order:
   - Start with AGENTIC-SDLC-DESIGN.md (the vision)
   - Then WORKFLOW-GATES-DESIGN.md (the mechanism)
   - Then AGENTIC-SDLC-PM-ADDENDUM.md (the operations)

2. **Flag questions and concerns** — docs are ready for markup/comments

3. **Resolve the 3 design decisions** above

4. **Prototype phase:** We'll build gate evaluator in isolation (the core algorithm) and test with examples before touching implementation

5. **Task decomposition:** Once design approved, PM breaks it into Phase 1 tasks for backend/QA/tech-writer

---

## What This Achieves

This SDLC + Workflow Gates design:

✅ Codifies real SDLC with enforceable gates (not just "best practices")  
✅ Enables fully autonomous agent teams with zero ceremonies  
✅ Provides automated feedback loops (rejection = signal, not failure)  
✅ Guarantees no stalls (timeouts + escalation)  
✅ Optimizes for Accelerate metrics (lead time, deployment frequency, failure rate)  
✅ Domain-neutral (works for sales, content, compliance later)  
✅ Agent-simple (just call `taskComplete()`)  
✅ Human-simple (~10 lines of YAML for basic workflow)  

This is the missing piece that turns AOF from a task queue into a real process orchestration system.

---

**Ready when you are.**
